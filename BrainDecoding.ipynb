{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mat73 in c:\\users\\mehrsystem\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.60)\n",
      "Requirement already satisfied: h5py in c:\\users\\mehrsystem\\appdata\\roaming\\python\\python310\\site-packages (from mat73) (3.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mehrsystem\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mat73) (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2\n",
      "[notice] To update, run: C:\\Users\\MehrSystem\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nibabel in c:\\users\\mehrsystem\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\users\\mehrsystem\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nibabel) (1.23.5)\n",
      "Requirement already satisfied: packaging>=17 in c:\\users\\mehrsystem\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nibabel) (23.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2\n",
      "[notice] To update, run: C:\\Users\\MehrSystem\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hdf5storage\n",
      "  Downloading hdf5storage-0.1.19-py2.py3-none-any.whl (53 kB)\n",
      "                                              0.0/53.6 kB ? eta -:--:--\n",
      "     ----------------------                   30.7/53.6 kB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 53.6/53.6 kB 556.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: h5py>=2.1 in c:\\users\\mehrsystem\\appdata\\roaming\\python\\python310\\site-packages (from hdf5storage) (3.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mehrsystem\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from hdf5storage) (1.23.5)\n",
      "Installing collected packages: hdf5storage\n",
      "Successfully installed hdf5storage-0.1.19\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2\n",
      "[notice] To update, run: C:\\Users\\MehrSystem\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install mat73\n",
    "%pip install nibabel\n",
    "%pip install hdf5storage"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\MehrSystem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\MehrSystem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from os.path import join as opj\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "import tqdm\n",
    "from torchsummary import summary\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from scipy.stats import hypergeom\n",
    "import seaborn as sns\n",
    "from termcolor import colored\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torchvision.utils import make_grid\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import nibabel.processing\n",
    "import pickle\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from god_decoding_utils import *\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "\n",
    "from PIL import Image\n",
    "import ast\n",
    "import matplotlib as plt\n",
    "import wandb\n",
    "from PIL import ImageFilter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data loading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Initialize sub and roi variables\n",
    "# You can change sub to each number in [1-5]\n",
    "sub = \"3\"\n",
    "roi = \"ROI_VC\"\n",
    "\n",
    "# Initialize kamitani_data_mat with the path to a file containing data for Subject 3\n",
    "kamitani_data_mat = f\"data/fMRI/GOD/Subject{sub}.h5\"\n",
    "\n",
    "# Initialize imagenet_dir with the path to a directory containing images\n",
    "imagenet_dir = \"data/fMRI/imagenet/images\"\n",
    "\n",
    "# Initialize test_img_csv and train_img_csv with the paths to two CSV files\n",
    "test_img_csv = 'data/fMRI/GOD/image_test_id.csv'\n",
    "train_img_csv = 'data/fMRI/GOD/image_training_id.csv'\n",
    "test_img_csv\n",
    "train_img_csv\n",
    "# Create a data_handler object using the specified arguments\n",
    "handler = data_handler(h5_file=kamitani_data_mat, test_img_csv=test_img_csv, train_img_csv=train_img_csv)\n",
    "\n",
    "# Get data using the get_data method of the handler object\n",
    "Y, Y_test, Y_test_avg = handler.get_data(normalize=1, roi=roi)\n",
    "\n",
    "# Get labels using the get_labels method of the handler object\n",
    "labels_train, labels = handler.get_labels()\n",
    "\n",
    "# Get filenames using the get_filenames method of the handler object\n",
    "filenames_train, filenames_test = handler.get_filenames()\n",
    "\n",
    "# Convert filenames_train and filenames_test from arrays to Python lists\n",
    "filenames_train = [i.item() for i in filenames_train]\n",
    "filenames_test = [i.item() for i in filenames_test]\n",
    "\n",
    "# Initialize an empty list called filenames_test_avg\n",
    "filenames_test_avg = []\n",
    "\n",
    "# Iterate 50 times\n",
    "for i in range(50):\n",
    "    # Append the first element from filenames_test whose label is equal to i to filenames_test_avg\n",
    "    filenames_test_avg.append(np.array(filenames_test)[labels==i][0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Wordnet mapping"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "with open('class_to_wordnet.json',) as f:\n",
    "    data = f.read()\n",
    "\n",
    "class2wordnet = ast.literal_eval(data)\n",
    "wordnet2class= {v[\"id\"] : k for k,v in class2wordnet.items()}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Initialize img_dir_path with the path to a directory containing training images\n",
    "img_dir_path = \"data/fMRI/imagenet/images/training\"\n",
    "\n",
    "# Initialize image_paths with a list of file paths to the training images\n",
    "image_paths = [os.path.join(img_dir_path, i) for i in filenames_train]\n",
    "\n",
    "# Initialize test_image_paths with a list of file paths to the test images\n",
    "test_image_paths = [os.path.join(imagenet_dir,\"test\", i) for i in filenames_test_avg]\n",
    "\n",
    "# Split the data into train and validation sets using the train_test_split function\n",
    "fmri_train, fmri_val, image_train, image_val = train_test_split(Y, image_paths, test_size=0.1, random_state=42)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset and Dataloaders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Initialize BS with the batch size\n",
    "BS = 64\n",
    "\n",
    "# Initialize normalize with a transformation that normalizes the data\n",
    "normalize = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# Initialize transform with a transformation that resizes and converts images to tensors\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.Resize(224),\n",
    "                                            torchvision.transforms.ToTensor(),\n",
    "                                            normalize])\n",
    "\n",
    "# Initialize train_dataset with a CustomDataset object using the fmri_train and image_train data and the transform\n",
    "train_dataset = CustomDataset(fmri_train, image_train, transform)\n",
    "\n",
    "# Initialize val_dataset with a CustomDataset object using the fmri_val and image_val data and the transform\n",
    "val_dataset = CustomDataset(fmri_val, image_val, transform)\n",
    "\n",
    "# Initialize test_dataset with a CustomDataset object using the Y_test_avg and test_image_paths data and the transform\n",
    "test_dataset = CustomDataset(Y_test_avg, test_image_paths, transform)\n",
    "\n",
    "# Initialize train_dataloader with a DataLoader object using the train_dataset and the specified batch size\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BS, shuffle=False)\n",
    "\n",
    "# Initialize val_dataloader with a DataLoader object using the val_dataset and the specified batch size\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=BS, shuffle=False)\n",
    "\n",
    "# Initialize test_dataloader with a DataLoader object using the test_dataset and the specified batch size\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BS, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MehrSystem\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MehrSystem\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained ResNet50 model from the torchvision library\n",
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "print(model)\n",
    "# Get the list of child modules of the model\n",
    "modules = list(model.children())\n",
    "\n",
    "# Remove the last element of the list of child modules\n",
    "modules = modules[:-1]\n",
    "\n",
    "# Create a new Sequential model using the remaining child modules\n",
    "model = nn.Sequential(*modules)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extract the latent representation for each image and store it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [01:19<00:00,  4.68s/it]\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.21s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.48s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty lists to store the data\n",
    "x_train = []\n",
    "z_train = []\n",
    "y_train = []\n",
    "\n",
    "x_val = []\n",
    "z_val = []\n",
    "y_val = []\n",
    "\n",
    "x_test = []\n",
    "z_test = []\n",
    "y_test = []\n",
    "\n",
    "# Iterate over the train_dataloader, val_dataloader, and test_dataloader\n",
    "# x are fMRI preprocessed data, y are the image stimuli\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm.tqdm(train_dataloader):\n",
    "        # Use the model to compute the latent representation of y\n",
    "        z = model(y)\n",
    "        # Append the data to the respective lists\n",
    "        x_train.append(x)\n",
    "        z_train.append(z.squeeze())\n",
    "        y_train.append(y)\n",
    "\n",
    "    for x, y in tqdm.tqdm(val_dataloader):\n",
    "        # Use the model to compute the latent representation of y\n",
    "        z = model(y)\n",
    "        # Append the data to the respective lists\n",
    "        x_val.append(x)\n",
    "        z_val.append(z.squeeze())\n",
    "        y_val.append(y)\n",
    "    for x, y in tqdm.tqdm(test_dataloader):\n",
    "        # Use the model to compute the latent representation of y\n",
    "        z = model(y)\n",
    "        # Append the data to the respective lists\n",
    "        x_test.append(x)\n",
    "        z_test.append(z.squeeze())\n",
    "        y_test.append(y)\n",
    "\n",
    "# Concatenate the lists of data into numpy arrays\n",
    "x_train = torch.cat(x_train, 0).numpy()\n",
    "z_train = torch.cat(z_train, 0).numpy()\n",
    "y_train = torch.cat(y_train, 0).numpy()\n",
    "\n",
    "x_val = torch.cat(x_val, 0).numpy()\n",
    "z_val = torch.cat(z_val, 0).numpy()\n",
    "y_val = torch.cat(y_val, 0).numpy()\n",
    "\n",
    "x_test = torch.cat(x_test, 0).numpy()\n",
    "z_test = torch.cat(z_test, 0).numpy()\n",
    "y_test = torch.cat(y_test, 0).numpy()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 2048)\n",
      "(50, 2048)\n",
      "(120, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(z_train.shape)\n",
    "print(z_test.shape)\n",
    "print(z_val.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Linear Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MehrSystem\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:255: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MehrSystem\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:255: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MehrSystem\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:255: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\MehrSystem\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:253: LinAlgWarning: Ill-conditioned matrix (rcond=7.74628e-20): result may not be accurate.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n",
      "C:\\Users\\MehrSystem\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:253: LinAlgWarning: Ill-conditioned matrix (rcond=2.51079e-19): result may not be accurate.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n",
      "C:\\Users\\MehrSystem\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:253: LinAlgWarning: Ill-conditioned matrix (rcond=7.38896e-17): result may not be accurate.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n",
      "C:\\Users\\MehrSystem\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:253: LinAlgWarning: Ill-conditioned matrix (rcond=8.06745e-17): result may not be accurate.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n",
      "C:\\Users\\MehrSystem\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:253: LinAlgWarning: Ill-conditioned matrix (rcond=7.5763e-17): result may not be accurate.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n",
      "C:\\Users\\MehrSystem\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:253: LinAlgWarning: Ill-conditioned matrix (rcond=7.58849e-17): result may not be accurate.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n",
      "C:\\Users\\MehrSystem\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:253: LinAlgWarning: Ill-conditioned matrix (rcond=7.61655e-17): result may not be accurate.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 10000}\n",
      "-0.18195555745550646\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ridge=Ridge(max_iter=5000)\n",
    "parameters={'alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,10,100,1000,10000,]}\n",
    "ridge_regressor=GridSearchCV(ridge,parameters,scoring='neg_mean_squared_error',cv=5)\n",
    "ridge_regressor.fit(x_train,z_train)\n",
    "\n",
    "print(ridge_regressor.best_params_)\n",
    "print(ridge_regressor.best_score_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "Ridge(alpha=10000, max_iter=5000)",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=10000, max_iter=5000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=10000, max_iter=5000)</pre></div></div></div></div></div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge(alpha=10000, max_iter=5000)\n",
    "\n",
    "ridge.fit(x_train, z_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse 0.03112794856925971\n",
      "rmse 0.20582907075477286\n",
      "rmse 0.2667757419987978\n",
      "rmse 0.16935964149718472\n"
     ]
    }
   ],
   "source": [
    "# Use the model to predict the latent representation of the test data\n",
    "pred_test_latent = ridge.predict(x_test)\n",
    "\n",
    "# Initialize epsilon with a small value\n",
    "epsilon = 1e-10\n",
    "\n",
    "# Standardize the predicted latent representation of the test data\n",
    "std_norm_test_latent = (pred_test_latent - np.mean(pred_test_latent, axis=0)) / (epsilon + np.std(pred_test_latent, axis=0))\n",
    "\n",
    "# Scale and shift the standardized predicted latent representation to match the scale and shift of the training data\n",
    "pred_instance = std_norm_test_latent * np.std(z_train, axis=0) + np.mean(z_train, axis=0)\n",
    "\n",
    "# Use the model to predict the latent representation of the training and validation data\n",
    "train_predicted = ridge.predict(x_train)\n",
    "val_predicted = ridge.predict(x_val)\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) of the predictions\n",
    "print(\"rmse\", mean_squared_error(z_train, train_predicted))\n",
    "print(\"rmse\", mean_squared_error(z_val, val_predicted))\n",
    "print(\"rmse\", mean_squared_error(z_test, pred_instance))\n",
    "print(\"rmse\", mean_squared_error(z_test, pred_test_latent))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Perceptron"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fmri_dim=x_train.shape[-1]\n",
    "latent_dim=z_train.shape[-1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_activation(activation):\n",
    "    if activation==\"relu\":\n",
    "        return nn.ReLU()\n",
    "\n",
    "    elif activation==\"gelu\":\n",
    "        return nn.GELU()\n",
    "\n",
    "    elif activation==\"tanh\":\n",
    "        return nn.Tanh()\n",
    "\n",
    "    elif activation==\"sigmoid\":\n",
    "        return nn.Sigmoid()\n",
    "\n",
    "    elif activation==\"selu\":\n",
    "        return nn.SELU()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class BrainMLP(nn.Module):\n",
    "    def __init__(self,latent_dim,hidden=[128],dropout=0.2,activation=\"gelu\"):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.model=[]\n",
    "        for h in hidden:\n",
    "            self.model.append(nn.LazyLinear(h))\n",
    "            self.model.append(get_activation(activation))\n",
    "\n",
    "\n",
    "        self.model.append(nn.Dropout(dropout))\n",
    "\n",
    "\n",
    "        self.model.append(nn.LazyLinear(latent_dim))\n",
    "\n",
    "        self.model=nn.Sequential(*self.model)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.model(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize a BrainMLP model with specified latent dimension, hidden layer sizes, dropout rate, and activation function\n",
    "brain_model = BrainMLP(latent_dim=latent_dim, hidden=[1024], dropout=0.3, activation=\"tanh\")\n",
    "\n",
    "# Print a summary of the model, including the input and output shapes and the number of parameters\n",
    "summary(brain_model, (fmri_dim,), device=\"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Convert the x_train, z_train, x_val, z_val, x_test, and z_test arrays to PyTorch tensors\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m train_brain_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mTensorDataset(torch\u001B[38;5;241m.\u001B[39mTensor(x_train), torch\u001B[38;5;241m.\u001B[39mTensor(z_train))\n\u001B[0;32m      3\u001B[0m val_brain_dataset \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mTensorDataset(torch\u001B[38;5;241m.\u001B[39mTensor(x_val), torch\u001B[38;5;241m.\u001B[39mTensor(z_val))\n\u001B[0;32m      4\u001B[0m test_brain_dataset \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mTensorDataset(torch\u001B[38;5;241m.\u001B[39mTensor(x_test), torch\u001B[38;5;241m.\u001B[39mTensor(z_test))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert the x_train, z_train, x_val, z_val, x_test, and z_test arrays to PyTorch tensors\n",
    "train_brain_dataset = torch.utils.data.TensorDataset(torch.Tensor(x_train), torch.Tensor(z_train))\n",
    "val_brain_dataset = torch.utils.data.TensorDataset(torch.Tensor(x_val), torch.Tensor(z_val))\n",
    "test_brain_dataset = torch.utils.data.TensorDataset(torch.Tensor(x_test), torch.Tensor(z_test))\n",
    "\n",
    "# Create DataLoaders for the training, validation, and test sets\n",
    "train_brain_dataloader = torch.utils.data.DataLoader(train_brain_dataset, batch_size=64, shuffle=True)\n",
    "val_brain_dataloader = torch.utils.data.DataLoader(val_brain_dataset, batch_size=64, shuffle=True)\n",
    "test_brain_dataloader = torch.utils.data.DataLoader(test_brain_dataset, batch_size=64, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'brain_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 12\u001B[0m\n\u001B[0;32m      9\u001B[0m gamma \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.5\u001B[39m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Move the brain model to the designated device\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m brain_model \u001B[38;5;241m=\u001B[39m \u001B[43mbrain_model\u001B[49m\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# Create an Adam optimizer with a weight decay of 1e-5\u001B[39;00m\n\u001B[0;32m     15\u001B[0m optim \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(brain_model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3e-3\u001B[39m, weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-5\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'brain_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Set the device to use for training\n",
    "device = \"cuda:0\"\n",
    "\n",
    "# Set the number of epochs to train for\n",
    "EPOCHS = 200\n",
    "\n",
    "# Set the step size and gamma for the learning rate scheduler\n",
    "scheduler_step = 60\n",
    "gamma = 0.5\n",
    "\n",
    "# Move the brain model to the designated device\n",
    "brain_model = brain_model.to(device)\n",
    "\n",
    "# Create an Adam optimizer with a weight decay of 1e-5\n",
    "optim = torch.optim.Adam(brain_model.parameters(), lr=3e-3, weight_decay=1e-5)\n",
    "\n",
    "# Create a learning rate scheduler that reduces the learning rate by a factor of gamma every scheduler_step epochs\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=scheduler_step, gamma=gamma)\n",
    "\n",
    "# Create a mean squared error loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Uncomment the following line to use a cosine embedding loss instead\n",
    "# criterion = nn.CosineEmbeddingLoss()\n",
    "# model=model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def train_brain_epoch(model, train_dataloader, criterion=None, optim=None, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Trains the model for one epoch using the specified dataloader and optimizer.\n",
    "\n",
    "    Parameters:\n",
    "    - model: PyTorch model to be trained\n",
    "    - train_dataloader: Dataloader for the training data\n",
    "    - criterion: Loss function to be used for training\n",
    "    - optim: Optimizer to be used for training\n",
    "    - device: Device to run the model and data on (CPU or GPU)\n",
    "\n",
    "    Returns:\n",
    "    - mean_loss: Mean loss of the model over the training data\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    loss_tmp = []\n",
    "    # Iterate over the training data\n",
    "    for x, y in train_dataloader:\n",
    "        # Zero the gradients of the optimizer\n",
    "        optim.zero_grad()\n",
    "        # Move the data to the specified device\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        # Get the model's prediction for the input data\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # Calculate the loss based on the criterion and model's prediction\n",
    "        if isinstance(criterion, nn.CosineEmbeddingLoss):\n",
    "            # Set the target to 1 if using the CosineEmbeddingL\n",
    "            target=torch.ones(y_pred.shape[0]).to(device)\n",
    "\n",
    "            loss=criterion(y_pred.squeeze(),y.squeeze(),target)\n",
    "\n",
    "        else:\n",
    "\n",
    "            loss=criterion(y_pred.squeeze(),y.squeeze())\n",
    "        # Backpropagate the loss and update the model's parameters\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        # Add the loss to the list of losses\n",
    "        loss_tmp.append(loss.item())\n",
    "    # Calculate the mean loss over all the data\n",
    "    mean_loss = np.mean(loss_tmp)\n",
    "    return mean_loss\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def val_brain_epoch(model, val_dataloader, criterion=None, optim=None, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Validates the model using the specified dataloader.\n",
    "\n",
    "    Parameters:\n",
    "    - model: PyTorch model to be validated\n",
    "    - val_dataloader: Dataloader for the validation data\n",
    "    - criterion: Loss function to be used for validation\n",
    "    - optim: Optimizer to be used for validation (not used in this function)\n",
    "    - device: Device to run the model and data on (CPU or GPU)\n",
    "\n",
    "    Returns:\n",
    "    - mean_loss: Mean loss of the model over the validation data\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    loss_tmp = []\n",
    "    i = 0\n",
    "    # Iterate over the validation data\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_dataloader:\n",
    "            # Move the data to the specified device\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            # Get the model's prediction for the input data\n",
    "            y_pred = model(x)\n",
    "            # Calculate the loss based on the criterion and model's prediction\n",
    "            if isinstance(criterion, nn.CosineEmbeddingLoss):\n",
    "                # Set the target to 1 if using the CosineEmbeddingLoss criterion\n",
    "                target = torch.ones(y_pred.shape[0]).to(device)\n",
    "                loss = criterion(y_pred.squeeze(), y.squeeze(), target)\n",
    "            else:\n",
    "                loss = criterion(y_pred.squeeze(), y.squeeze())\n",
    "            # Add the loss to the list of losses\n",
    "            loss_tmp.append(loss.item())\n",
    "    # Calculate the mean loss over all the data\n",
    "    mean_loss = np.mean(loss_tmp)\n",
    "    return mean_loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_history=[]\n",
    "val_loss_history=[]\n",
    "\n",
    "# frequency of validation\n",
    "val_freq=1\n",
    "\n",
    "train = True\n",
    "# if train is set to True, train the model\n",
    "if train:\n",
    "    # create a progress bar\n",
    "    pbar=tqdm.tqdm(range(EPOCHS))\n",
    "    # iterate over the number of epochs\n",
    "    for epoch in pbar:\n",
    "        # call the train_brain_epoch function to train the model for one epoch\n",
    "        loss=train_brain_epoch(brain_model,train_dataloader=train_brain_dataloader,criterion=criterion,optim=optim,device=device)\n",
    "\n",
    "        # step the scheduler to adjust the learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        # append the loss to the loss history\n",
    "        loss_history.append(loss)\n",
    "\n",
    "        # if the current epoch is a multiple of val_freq, call the val_brain_epoch function to get the validation loss\n",
    "        if epoch%val_freq==0:\n",
    "            val_loss=val_brain_epoch(brain_model,val_dataloader=val_brain_dataloader,criterion=criterion,optim=optim,device=device)\n",
    "            val_loss_history.append(val_loss)\n",
    "\n",
    "        # update the progress bar description with the current epoch and loss information\n",
    "        if epoch>val_freq:\n",
    "            pbar.set_description(f\"[INFO] epoch: {epoch} loss: {loss_history[-1]} val_loss: {val_loss_history[-1]}\")\n",
    "        else:\n",
    "            pbar.set_description(f\"[INFO] epoch: {epoch} loss: {loss_history[-1]}\")\n",
    "\n",
    "\n",
    "    #save final weights\n",
    "    torch.save(brain_model.state_dict(),f\"models/brain_model_weights_sub{sub}.pt\")\n",
    "\n",
    "else:\n",
    "    #load pretrained models\n",
    "\n",
    "    brain_model.load_state_dict(torch.load(f\"models/brain_model_weights_sub{sub}.pt\"))\n",
    "    brain_model=brain_model.to(device)\n",
    "    ridge = pickle.load(open(f\"models/ridge_sub{sub}.sav\", 'rb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if train:\n",
    "    plt.plot(loss_history,label=\"loss\")\n",
    "    plt.plot(val_loss_history,label=\"val_loss\")\n",
    "    plt.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize variables for predictions on train, val, and test sets\n",
    "train_predict = None\n",
    "val_predict = None\n",
    "test_predict = None\n",
    "\n",
    "# Turn off gradient calculation\n",
    "with torch.no_grad():\n",
    "  # Make predictions on train set\n",
    "  train_predict = brain_model(torch.Tensor(x_train).to(device)).cpu().numpy()\n",
    "  # Make predictions on val set\n",
    "  val_predict = brain_model(torch.Tensor(x_val).to(device)).cpu().numpy()\n",
    "  # Make predictions on test set\n",
    "  test_predict = brain_model(torch.Tensor(x_test).to(device)).cpu().numpy()\n",
    "\n",
    "  # Standardize test predictions\n",
    "  std_norm_test_latent = (test_predict - np.mean(test_predict, axis=0)) / np.std(test_predict, axis=0)\n",
    "  # Adjust test predictions using mean and std of training set\n",
    "  test_predicted_adjusted = std_norm_test_latent * np.std(z_train, axis=0) + np.mean(z_train, axis=0)\n",
    "\n",
    "# Calculate and print root mean squared error for train, val, and test sets\n",
    "print(\"rmse\", mean_squared_error(z_train, train_predict))\n",
    "print(\"rmse\", mean_squared_error(z_val, val_predict))\n",
    "print(\"rmse\", mean_squared_error(z_test, test_predicted_adjusted))\n",
    "print(\"rmse\", mean_squared_error(z_test, test_predict))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
